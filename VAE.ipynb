{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers,Model,utils\n",
    "import imageio\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,labels),(_,_)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data=data.astype('float32')\n",
    "    data/=255\n",
    "    data[data>0.5]=1\n",
    "    data[data<=0.5]=0\n",
    "    return tf.expand_dims(data,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = preprocess_data(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = np.eye(10)[labels]\n",
    "one_hot_labels=tf.cast(one_hot_labels,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_images,one_hot_labels)).batch(64).shuffle(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(Model):\n",
    "    def __init__(self,n_filters):\n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(n_filters,kernel_size=3,strides=(2,2),padding = 'same',activation = 'elu')\n",
    "        self.conv2 = layers.Conv2D(n_filters*2,kernel_size=3,strides=(2,2),padding = 'same',activation = 'elu')\n",
    "        self.flat = layers.Flatten()\n",
    "        self.bottle_neck = layers.Dense(50+50)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        #dim = (64,28,28,1)\n",
    "        x = self.conv1(inputs)\n",
    "        #dim = (64,14,14,16)\n",
    "        x = self.conv2(x)\n",
    "        #dim = (64,7,7,32)\n",
    "        x = self.flat(x)\n",
    "        #dim = (64,7*7*32)\n",
    "        x = self.bottle_neck(x)\n",
    "        #dim = (64,50+50)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(Model):\n",
    "    def __init__(self,n_filters):\n",
    "        super(Classifier,self).__init__()\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(n_filters,kernel_size=3,strides=(2,2),padding = 'same',activation = 'elu')\n",
    "        self.conv2 = layers.Conv2D(n_filters*2,kernel_size=3,strides=(2,2),padding = 'same',activation = 'elu')\n",
    "        self.flat = layers.Flatten()\n",
    "        self.bottle_neck = layers.Dense(10)\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        #dim = (64,28,28,1)\n",
    "        x = self.conv1(inputs)\n",
    "        #dim = (64,14,14,16)\n",
    "        x = self.conv2(x)\n",
    "        #dim = (64,7,7,32)\n",
    "        x = self.flat(x)\n",
    "        #dim = (64,7*7*32)\n",
    "        x = self.bottle_neck(x)\n",
    "        #dim = (64,10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(Model):\n",
    "    def __init__(self,n_filters):\n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "        self.dense = layers.Dense(7*7*32,activation='elu')\n",
    "        self.reshape = layers.Reshape(target_shape=(7,7,32))\n",
    "        self.deconv1 = layers.Conv2DTranspose(n_filters*2,kernel_size=3,strides=(2,2),padding = 'same',activation = 'elu')\n",
    "        self.deconv2 = layers.Conv2DTranspose(n_filters,kernel_size=3,strides=(2,2),padding = 'same',activation = 'elu')\n",
    "        self.decoder_output = layers.Conv2D(1,kernel_size=3,strides=(1,1),padding = 'same')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        #z_dim = (64,60)\n",
    "        x = self.dense(inputs)\n",
    "        #dim = (64,7*7*32)\n",
    "        x = self.reshape(x)\n",
    "        #dim = (64,7,7,32)\n",
    "        x = self.deconv1(x)\n",
    "        #dim = (64,7,7,32)\n",
    "        x = self.deconv2(x)\n",
    "        #dim = (64,14,14,16)\n",
    "        x = self.decoder_output(x)\n",
    "        #dim = (64,28*28*1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def reparameterize(input_tensor):\n",
    "    # inputs have dim (64,50+50) where the first 50 params are mean and the next 50 is logvar\n",
    "    mean = input_tensor[:,:50]\n",
    "    logvar = input_tensor[:,50::]\n",
    "    \n",
    "    sample = tf.random.normal((input_tensor.shape[0],50))\n",
    "    z = mean+tf.math.sqrt(tf.exp(logvar))*sample \n",
    "    return z,mean,logvar,sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal(mean,logvar,sample):\n",
    "    return tf.reduce_sum(-0.5*((sample-mean)**2*tf.exp(-logvar)+tf.math.log(2*np.pi)+logvar),axis=1)\n",
    "\n",
    "@tf.function\n",
    "def compute_loss(input_image,generated_image,predicted_labels,true_labels,mean,logvar,sample,alpha=1.0):\n",
    "    logpz=log_normal(0.0,1.0,sample)\n",
    "    logqz = log_normal(mean,logvar,sample)\n",
    "    logpx_z = -tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=generated_image,labels=input_image),axis = [1,2,3])\n",
    "    inference_loss = -tf.reduce_mean(logpx_z+logpz-logqz)\n",
    "    class_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = predicted_labels,labels = true_labels))\n",
    "    return alpha*class_loss+inference_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(16)\n",
    "encoder = Encoder(16)\n",
    "decoder =Decoder(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = r'C:/Users/Boyang/Machine Learning/VAE/logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = r'C:/Users/Boyang/Machine Learning/VAE/logs/gradient_tape/' + current_time + '/test'\n",
    "#train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "#test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Boyang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(1e-4)\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "\n",
    "@tf.function()\n",
    "def train_step(image,labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_labels = classifier(image)\n",
    "        encoder_output = encoder(image)\n",
    "        z,mean,logvar,sample = reparameterize(encoder_output)\n",
    "        generated_image = decoder(tf.concat([z,predicted_labels],axis = 1))\n",
    "        loss = compute_loss(image,generated_image,predicted_labels,labels,mean,logvar,sample,alpha=10.0)\n",
    "        \n",
    "    train_loss(loss)\n",
    "    \n",
    "    gradients = tape.gradient(loss,(classifier.trainable_variables+encoder.trainable_variables+decoder.trainable_variables))\n",
    "    adam.apply_gradients(zip(gradients,(classifier.trainable_variables+encoder.trainable_variables+decoder.trainable_variables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "__iter__() is only supported inside of tf.function or when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-8bcee18d03f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2033\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2034\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    341\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIteratorV2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[0;32m    344\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "checkpoint_path = r\"C:/Users/Boyang/Machine Learning/VAE/VAE_saved_models\"\n",
    "generated_samples = []\n",
    "for epoch in range(1,101):\n",
    "    start_time = time.time()\n",
    "    for step,image,label in enumerate(dataset):\n",
    "        train_step(image,label)\n",
    "    end_time = time.time()\n",
    "    if epoch % 10 == 0:\n",
    "        test_inputs = tf.concat([tf.random.normal((10,50)),tf.cast(np.eye(10)[0:10],'float32')],axis = 1)\n",
    "\n",
    "        print('Epoch: {},  time elapse for current epoch {}'.format(epoch,end_time - start_time))\n",
    "        encoder.save_weights(checkpoint_path+'encoder_{}.h5'.format(epoch))\n",
    "        decoder.save_weights(checkpoint_path+'decoder_{}.h5'.format(epoch))\n",
    "        classifier.save_weights(checkpoint_path+'classifer_{}.h5'.format(epoch))\n",
    "        generated_samples.append(decoder(test_inputs))\n",
    "        \n",
    "encoder.save_weights(checkpoint_path+'encoder_{}.h5'.format(epoch))\n",
    "decoder.save_weights(checkpoint_path+'decoder_{}.h5'.format(epoch))\n",
    "classifier.save_weights(checkpoint_path+'classifer_{}.h5'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
