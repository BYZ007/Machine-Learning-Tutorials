{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential,Model,layers,utils\n",
    "import os\n",
    "import re\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = utils.get_file('Cornell_Movie-Dialogs_Corpus.zip',origin= 'https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.zip',extract = True)\n",
    "data_path = os.path.join(os.path.dirname(path),'cornell movie-dialogs corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove unnecessary characters, and to put a space between each punctuation and word\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"([,.?!])\",r\" \\1 \",text)\n",
    "    text = re.sub(r\"[' ']+\",r\" \",text)\n",
    "    text = re.sub(r\"[^,.?!a-zA-Z]\",r\" \",text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "\n",
      "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
      "\n",
      "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
      "\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path,'movie_lines.txt'),errors = 'ignore') as file:\n",
    "    lines = file.readlines()\n",
    "for i in range(3):\n",
    "    print(lines[i])\n",
    "    \n",
    "with open(os.path.join(data_path,'movie_conversations.txt')) as file:\n",
    "    lines = file.readlines()\n",
    "for i in range(3):\n",
    "    print(lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the questions and answers into staggered sets of lists/sequences\n",
    "# the answer to the previous question is the the question to the next sequence\n",
    "\n",
    "def load_lines():\n",
    "    \n",
    "    with open(os.path.join(data_path,'movie_lines.txt'),errors = 'ignore') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    IDs = {}\n",
    "    for line in lines:\n",
    "        lineID = line.split(' +++$+++ ')[0]\n",
    "        line = line.split(' +++$+++ ')[-1]\n",
    "        IDs[lineID] = line\n",
    "        \n",
    "    with open(os.path.join(data_path,'movie_conversations.txt')) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    questions,answers = [],[]\n",
    "    for line in lines:\n",
    "        line_ids = line.split(' +++$+++ ')[-1]\n",
    "        line_ids = re.findall(r\"'(L\\d+)'\",line_ids)\n",
    "        \n",
    "        for i in range(len(line_ids)-1):\n",
    "            questions.append(preprocess(IDs[line_ids[i]]))\n",
    "            answers.append(preprocess(IDs[line_ids[i+1]]))\n",
    "    \n",
    "    return questions,answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions,answers = load_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like you , joey . you ask all the right questions . there is something we can do but it will require great courage .\n",
      "i don t know . . .\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.choice(len(questions))\n",
    "print(questions[sample])\n",
    "print(answers[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(questions+answers, target_vocab_size = 2**13)\n",
    "start_token,end_token = [tokenizer.vocab_size],[tokenizer.vocab_size+1]\n",
    "VocabSize = tokenizer.vocab_size+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(questions,answers):\n",
    "    tokenized_questions,tokenized_answers = [],[]\n",
    "    \n",
    "    global max_seq_len\n",
    "    max_seq_len = 40\n",
    "    \n",
    "    for (q,a) in zip(questions,answers):\n",
    "        encoded_q = tokenizer.encode(q)\n",
    "        encoded_a = tokenizer.encode(a)\n",
    "        if len(encoded_q)+2<=max_seq_len and len(encoded_a)+2<=max_seq_len:\n",
    "        \n",
    "            tokenized_questions.append(start_token + encoded_q + end_token)\n",
    "            tokenized_answers.append(start_token + encoded_a + end_token)\n",
    "        \n",
    "    tokenized_questions = tf.keras.preprocessing.sequence.pad_sequences(tokenized_questions,maxlen=max_seq_len,padding = 'post')\n",
    "    tokenized_answers = tf.keras.preprocessing.sequence.pad_sequences(tokenized_answers,maxlen=max_seq_len,padding = 'post')\n",
    "    \n",
    "    return tokenized_questions,tokenized_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_questions,tokenized_answers = tokenize(questions,answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193686\n",
      "8158\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "buffer = len(tokenized_questions)\n",
    "print(buffer)\n",
    "print(VocabSize)\n",
    "print(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffersize = 20000\n",
    "batchsize = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tokenized_questions,tokenized_answers))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(buffersize)\n",
    "dataset = dataset.batch(batchsize,drop_remainder = True)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self,d,n_heads):\n",
    "        super(AttentionLayer,self).__init__()\n",
    "        \n",
    "        self.ValueLayer = layers.Dense(d)\n",
    "        self.KeyLayer = layers.Dense(d)\n",
    "        self.QueryLayer = layers.Dense(d)\n",
    "        self.d = d\n",
    "        self.n = n_heads\n",
    "        self.layer_output = layers.Dense(d)\n",
    "        \n",
    "        assert d%n_heads == 0\n",
    "        self.depth = d//n_heads\n",
    "        \n",
    "    def multiheads(self,input_tensor):\n",
    "        \n",
    "        # input dim = (batchsize,seq_len,d)\n",
    "        multiheaded_tensor = tf.reshape(input_tensor,shape=(batchsize,-1,self.n,self.depth))\n",
    "        multiheaded_tensor = tf.transpose(multiheaded_tensor,perm = [0,2,1,3])\n",
    "        # output dim = (batch_size,n_heads,seq_len,depth)\n",
    "        \n",
    "        return multiheaded_tensor\n",
    "                \n",
    "    def attention(self,V,K,Q,mask):\n",
    "        \n",
    "        # input dim = (batchsize,n_heads,seq_len,depth)\n",
    "        QdotK = tf.matmul(Q,K,transpose_b=True)*(self.depth)**-0.5\n",
    "        # QdotK dim = (batchsize,n_heads,seq_lenQ,seq_lenk)\n",
    "        \n",
    "        if not (mask==None):\n",
    "            QdotK += mask*-1e9\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(QdotK,axis = -1)\n",
    "        \n",
    "        context_vector = tf.matmul(attention_weights,V)\n",
    "        # output dim = (batchsize,n_heads,seq_lenQ,depth)\n",
    "        \n",
    "        return context_vector\n",
    "    \n",
    "    def call(self,value,key,query,mask):\n",
    "        \n",
    "        V = self.multiheads(self.ValueLayer(value))\n",
    "        K = self.multiheads(self.KeyLayer(key))\n",
    "        Q = self.multiheads(self.QueryLayer(query))\n",
    "        \n",
    "        context_vector = self.attention(V,K,Q,mask)\n",
    "        context_vector = tf.transpose(context_vector,perm = [0,2,1,3])\n",
    "        context_vector = tf.reshape(context_vector,shape = (batchsize,-1,self.d))\n",
    "        # context vector/output dims = (batchsize,seq_lenQ,d)\n",
    "        \n",
    "        outputs = self.layer_output(context_vector)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self,d,n_heads,dff):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        \n",
    "        self.attention = AttentionLayer(d,n_heads)\n",
    "        \n",
    "        self.feedforward1 = layers.Dense(dff,activation = 'relu')\n",
    "        self.feedforward2 = layers.Dense(d)\n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = layers.Dropout(rate = 0.3)\n",
    "        self.dropout2 = layers.Dropout(rate = 0.3)\n",
    "        \n",
    "    def call(self,inputs,mask):\n",
    "        \n",
    "        attention_vector = self.attention(inputs,inputs,inputs,mask)\n",
    "        attention_vector = self.dropout1(attention_vector,training=True)\n",
    "        output1 = self.norm1(attention_vector+inputs)\n",
    "        \n",
    "        output2 = self.feedforward1(output1)\n",
    "        output2 = self.feedforward2(output2)\n",
    "        output2 = self.dropout2(output2,training = True)\n",
    "        output2 = self.norm2(output2 + output1)\n",
    "        \n",
    "        return output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(input_tensor):\n",
    "    \n",
    "    # input dim = (batchsize,seq_len,d), for each value in d iterate i\n",
    "    i = np.arange(input_tensor.shape[-1],dtype = 'float32')\n",
    "    pos = np.arange(input_tensor.shape[1],dtype = 'float32')\n",
    "    \n",
    "    # desired encoding dim = (1,seq_len,d)\n",
    "    angle_rates = 1/(1e4**(2*(i//2)/np.float32(len(i))))\n",
    "    angles = np.einsum('i,j->ij',pos,angle_rates)\n",
    "    evens = np.sin(angles[:,0::2])\n",
    "    odds = np.cos(angles[:,1::2])\n",
    "    pos_encoding = np.concatenate([evens,odds],axis = 1)\n",
    "    return input_tensor+pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    \n",
    "    def __init__(self,d,n_heads,n_layers,dff):\n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(d,n_heads,dff) for i in range(n_layers)]\n",
    "        self.embed = layers.Embedding(VocabSize,d)\n",
    "        self.n_layers=n_layers\n",
    "        \n",
    "    def call(self,inputs,mask):\n",
    "        \n",
    "        embedded_inputs = self.embed(inputs)\n",
    "        pos_encoded_inputs = positional_encoding(embedded_inputs)\n",
    "        enc_output = pos_encoded_inputs\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            enc_output = self.encoder_layers[i](enc_output,mask)\n",
    "            \n",
    "        assert enc_output.shape == (batchsize,max_seq_len,d)\n",
    "        return enc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self,d,n_heads,dff):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        \n",
    "        self.feedforward1 = layers.Dense(dff,activation = 'relu')\n",
    "        self.feedforward2 = layers.Dense(d)\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(0.3)\n",
    "        self.dropout2 = layers.Dropout(0.3)\n",
    "        self.dropout3 = layers.Dropout(0.3)\n",
    "        self.self_attention = AttentionLayer(d,n_heads)\n",
    "        self.attention = AttentionLayer(d,n_heads)\n",
    "        \n",
    "    def call(self,enc_output,dec_input,forward_mask,padding_mask):\n",
    "        \n",
    "        output1 = self.self_attention(dec_input,dec_input,dec_input,forward_mask)\n",
    "        output1 = self.dropout1(output1,training = True)\n",
    "        output1 = self.norm1(dec_input+output1)\n",
    "        \n",
    "        output2 = self.attention(enc_output,enc_output,output1,padding_mask)\n",
    "        output2 = self.dropout2(output2,training = True)\n",
    "        output2 = self.norm2(output1+output2)\n",
    "        \n",
    "        output3 = self.feedforward1(output2)\n",
    "        output3 = self.feedforward2(output3)\n",
    "        output3 = self.dropout3(output3,training = True)\n",
    "        output3 = self.norm3(output2+output3)\n",
    "        \n",
    "        return output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    \n",
    "    def __init__(self,d,n_heads,n_layers,dff):\n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "        self.embbed = layers.Embedding(VocabSize,d)\n",
    "        self.decoder_layers = [DecoderLayer(d,n_heads,dff) for i in range(n_layers)]\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "    def call(self,enc_output,dec_input,forward_mask,padding_mask):\n",
    "        \n",
    "        dec_input = self.embbed(dec_input)\n",
    "        dec_input = positional_encoding(dec_input)\n",
    "        dec_output = dec_input\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            dec_output = self.decoder_layers[i](enc_output,dec_output,forward_mask,padding_mask)\n",
    "        \n",
    "        assert dec_output.shape == (batchsize,max_seq_len-1,d)\n",
    "        return dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(Model):\n",
    "    \n",
    "    def __init__(self,d,n_heads,n_layers,dff):\n",
    "        super(Transformer,self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(d,n_heads,n_layers,dff)\n",
    "        self.decoder = Decoder(d,n_heads,n_layers,dff)\n",
    "        self.final_layer = layers.Dense(VocabSize)\n",
    "        \n",
    "    def build_mask(self,input_tensor,mask_type):\n",
    "        \n",
    "        # input tensor dim = (batchsize,seq_len)\n",
    "        # desired output dim = (batchsize,1,1,seq_len) since dim QK is (batchsize,n_heads,seq_lenQ,seq_lenK)\n",
    "        # the masking needs to be with respect to the key\n",
    "        padding_mask = tf.cast(tf.math.equal(input_tensor,0),'float32')\n",
    "        padding_mask = padding_mask[:,tf.newaxis,tf.newaxis,:]\n",
    "        if mask_type == 'padding':\n",
    "            return padding_mask\n",
    "            \n",
    "        # the masking needs to take only the lower triangular \n",
    "        # since the sequence in Q_n should only have access to K_n-1,K_n-2...K_1\n",
    "        # look_forward_mask should be dim = (1,1,seq_lenQ,seq_lenK)\n",
    "        elif mask_type == 'forward':\n",
    "            seq_len = tf.cast(input_tensor.shape[-1],'float32')\n",
    "            forward_mask = tf.cast(1-tf.linalg.band_part(tf.ones((seq_len,seq_len)),-1,0),'float32')\n",
    "            forward_mask = tf.maximum(forward_mask,padding_mask)\n",
    "            return forward_mask\n",
    "            \n",
    "    def call(self,enc_inputs,dec_inputs):\n",
    "        \n",
    "        padding_mask = self.build_mask(enc_inputs,'padding')\n",
    "        forward_mask = self.build_mask(dec_inputs,'forward')\n",
    "        \n",
    "        enc_outputs = self.encoder(enc_inputs,padding_mask)\n",
    "        dec_outputs = self.decoder(enc_outputs,dec_inputs,forward_mask,padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_outputs)\n",
    "        \n",
    "        return final_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 6\n",
    "d = 512\n",
    "dff = 1024\n",
    "n_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \n",
    "    def __init__(self,d,warmup = 4000):\n",
    "        super(CustomSchedule,self).__init__()\n",
    "        \n",
    "        self.d = tf.cast(d,'float32')\n",
    "        self.warmup = tf.cast(warmup,'float32')\n",
    "        \n",
    "    def __call__(self,step):\n",
    "        lr = tf.math.minimum(step**-0.5,step*self.warmup**-1.5)*self.d**-0.5\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate,beta_1=0.9,beta_2=0.98,epsilon=1e-9)\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')\n",
    "\n",
    "def compute_loss(dec_targets,dec_out):\n",
    "    mask = tf.math.logical_not(tf.math.equal(dec_targets,0))\n",
    "    loss = loss_function(dec_targets,dec_out)\n",
    "    \n",
    "    mask = tf.cast(mask,'float32')\n",
    "    loss*=mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(d, n_heads,n_layers, dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(encoder_inputs,decoder_inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = transformer(encoder_inputs,decoder_inputs[:,:-1])\n",
    "        \n",
    "        loss = compute_loss(decoder_inputs[:,1:],predictions)\n",
    "        \n",
    "    gradient = tape.gradient(loss,transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradient,transformer.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(decoder_inputs[:,1:], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 99 Loss 1.9894 Accuracy 0.0305\n",
      "Time taken for batches: 2.3985860347747803 secs\n",
      "\n",
      "Epoch 1 Batch 199 Loss 1.9758 Accuracy 0.0305\n",
      "Time taken for batches: 2.4045698642730713 secs\n",
      "\n",
      "Epoch 1 Batch 299 Loss 1.9683 Accuracy 0.0305\n",
      "Time taken for batches: 2.4364845752716064 secs\n",
      "\n",
      "Epoch 1 Batch 399 Loss 1.9627 Accuracy 0.0305\n",
      "Time taken for batches: 2.374650001525879 secs\n",
      "\n",
      "Epoch 1 Batch 499 Loss 1.9633 Accuracy 0.0305\n",
      "Time taken for batches: 2.38661789894104 secs\n",
      "\n",
      "Epoch 1 Batch 599 Loss 1.9597 Accuracy 0.0306\n",
      "Time taken for batches: 2.407562732696533 secs\n",
      "\n",
      "Epoch 1 Batch 699 Loss 1.9601 Accuracy 0.0306\n",
      "Time taken for batches: 2.415541172027588 secs\n",
      "\n",
      "Epoch 1 Batch 799 Loss 1.9655 Accuracy 0.0306\n",
      "Time taken for batches: 2.393599271774292 secs\n",
      "\n",
      "Epoch 1 Batch 899 Loss 1.9669 Accuracy 0.0306\n",
      "Time taken for batches: 2.4255142211914062 secs\n",
      "\n",
      "Epoch 1 Batch 999 Loss 1.9635 Accuracy 0.0306\n",
      "Time taken for batches: 2.42750883102417 secs\n",
      "\n",
      "Epoch 1 Batch 1099 Loss 1.9648 Accuracy 0.0306\n",
      "Time taken for batches: 2.432494640350342 secs\n",
      "\n",
      "Epoch 1 Batch 1199 Loss 1.9638 Accuracy 0.0307\n",
      "Time taken for batches: 2.4344890117645264 secs\n",
      "\n",
      "Epoch 1 Batch 1299 Loss 1.9593 Accuracy 0.0306\n",
      "Time taken for batches: 2.4205262660980225 secs\n",
      "\n",
      "Epoch 1 Batch 1399 Loss 1.9567 Accuracy 0.0306\n",
      "Time taken for batches: 2.42551326751709 secs\n",
      "\n",
      "Epoch 1 Batch 1499 Loss 1.9552 Accuracy 0.0306\n",
      "Time taken for batches: 2.429503917694092 secs\n",
      "\n",
      "Epoch 1 Batch 1599 Loss 1.9542 Accuracy 0.0306\n",
      "Time taken for batches: 2.596057415008545 secs\n",
      "\n",
      "Epoch 1 Batch 1699 Loss 1.9519 Accuracy 0.0306\n",
      "Time taken for batches: 2.4444634914398193 secs\n",
      "\n",
      "Epoch 1 Batch 1799 Loss 1.9528 Accuracy 0.0307\n",
      "Time taken for batches: 2.4574291706085205 secs\n",
      "\n",
      "Epoch 1 Batch 1899 Loss 1.9513 Accuracy 0.0307\n",
      "Time taken for batches: 2.4374825954437256 secs\n",
      "\n",
      "Epoch 1 Batch 1999 Loss 1.9500 Accuracy 0.0307\n",
      "Time taken for batches: 2.4474551677703857 secs\n",
      "\n",
      "Epoch 1 Batch 2099 Loss 1.9485 Accuracy 0.0307\n",
      "Time taken for batches: 2.447455406188965 secs\n",
      "\n",
      "Epoch 1 Batch 2199 Loss 1.9482 Accuracy 0.0307\n",
      "Time taken for batches: 2.451444387435913 secs\n",
      "\n",
      "Epoch 1 Batch 2299 Loss 1.9488 Accuracy 0.0307\n",
      "Time taken for batches: 2.4634125232696533 secs\n",
      "\n",
      "Epoch 1 Batch 2399 Loss 1.9497 Accuracy 0.0307\n",
      "Time taken for batches: 2.438478469848633 secs\n",
      "\n",
      "Epoch 1 Batch 2499 Loss 1.9498 Accuracy 0.0307\n",
      "Time taken for batches: 2.453439235687256 secs\n",
      "\n",
      "Epoch 1 Batch 2599 Loss 1.9502 Accuracy 0.0307\n",
      "Time taken for batches: 2.453439474105835 secs\n",
      "\n",
      "Epoch 1 Batch 2699 Loss 1.9514 Accuracy 0.0308\n",
      "Time taken for batches: 2.4434657096862793 secs\n",
      "\n",
      "Epoch 1 Batch 2799 Loss 1.9527 Accuracy 0.0308\n",
      "Time taken for batches: 2.452441930770874 secs\n",
      "\n",
      "Epoch 1 Batch 2899 Loss 1.9544 Accuracy 0.0308\n",
      "Time taken for batches: 2.487348794937134 secs\n",
      "\n",
      "Epoch 1 Batch 2999 Loss 1.9554 Accuracy 0.0308\n",
      "Time taken for batches: 2.4474544525146484 secs\n",
      "\n",
      "Epoch 1 Loss 1.9553 Accuracy 0.0308\n",
      "Epoch 2 Batch 99 Loss 1.9729 Accuracy 0.0311\n",
      "Time taken for batches: 2.459423065185547 secs\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-0cb90f4b7d83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    402\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    587\u001b[0m     \"\"\"\n\u001b[0;32m    588\u001b[0m     return self._call_flat(\n\u001b[1;32m--> 589\u001b[1;33m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[0;32m    590\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m    591\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 445\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    446\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(4):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    for (batch,(encoder_inputs,decoder_inputs)) in enumerate(dataset):\n",
    "        start = time.time()\n",
    "        train_step(encoder_inputs,decoder_inputs)\n",
    "        \n",
    "        if (batch+1) % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "            print ('Time taken for batches: {} secs\\n'.format(time.time() - start))\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, train_loss.result(), train_accuracy.result()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
