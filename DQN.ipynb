{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,layers,Sequential,utils\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self,n=15,goal=5):\n",
    "        self.n = n\n",
    "        self.goal = goal\n",
    "        self.board = np.zeros((n,n))\n",
    "        self.winner = None\n",
    "        \n",
    "    def is_empty(self,i,j):\n",
    "        if self.board[i,j]==0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def kernel_check(self,kernel):\n",
    "        for i in range(self.goal):\n",
    "            if (sum(kernel[i,:]) == self.goal) or (sum(kernel[:,i])==self.goal):\n",
    "                self.winner = 1\n",
    "                return True\n",
    "            elif (sum(kernel[i,:]) == -self.goal) or (sum(kernel[:,i])==-self.goal):\n",
    "                self.winner = -1\n",
    "                return True\n",
    "            \n",
    "        if (kernel.trace() == self.goal) or (kernel[::-1].trace()==self.goal):\n",
    "            self.winner = 1\n",
    "            return True\n",
    "        elif (kernel.trace() == -self.goal) or (kernel[::-1].trace()==-self.goal):\n",
    "            self.winner = -1\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def game_over(self):\n",
    "        if not 0 in self.board:\n",
    "            return True\n",
    "        k = self.n-self.goal+1\n",
    "        for i in range(k):\n",
    "            for j in range(k):\n",
    "                kernel = self.board[i:i+5,j:j+5]\n",
    "                if self.kernel_check(kernel):\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def rewards(self,agent):\n",
    "        if self.winner == agent.piece:\n",
    "            return 1\n",
    "        elif self.winner == None:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    def get_state(self,board):\n",
    "        vector = np.ndarray.flatten(board.copy())\n",
    "        state = 0\n",
    "        for i in range(len(vector)):\n",
    "            state+=vector[i]*3**i\n",
    "        return state\n",
    "    \n",
    "    def get_board(self,state):\n",
    "        vector = np.zeros(self.n**2)\n",
    "        for i in range(len(vector)):\n",
    "            vector[i]=state%3\n",
    "            state//=3\n",
    "        vector[vector == 2]=-1\n",
    "        return np.reshape(vector,(self.n,self.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,sym,env,Qvalue,Qtarget,buffersize = 10000,epsilon = 1,):\n",
    "        if sym == 'x':\n",
    "            self.piece = 1\n",
    "        elif sym == 'o':\n",
    "            self.piece = -1\n",
    "        \n",
    "        self.replay_buffer = []\n",
    "        self.Qvalue = Qvalue\n",
    "        self.Qtarget = Qtarget\n",
    "        self.e = epsilon\n",
    "        self.batch = None\n",
    "        \n",
    "    def valid_mask(self,board):\n",
    "        mask = np.ndarray.flatten(board.copy())\n",
    "        mask[mask!=0]=1\n",
    "        return\n",
    "    \n",
    "    def move(self):\n",
    "        mask = self.valid_mask(self.env.board)\n",
    "        valid_moves = np.where(mask==0)\n",
    "        current_state = self.env.get_state(self.env.board)\n",
    "        n = np.random.rand(0,1)\n",
    "        if n<=self.e:\n",
    "            next_move = np.random.choice(valid_moves)\n",
    "\n",
    "        else:\n",
    "            best_value = -1\n",
    "            for move in valid_moves:\n",
    "                next_state = current_state+3**move\n",
    "                Qvalue = self.Qvalue(self.env.get_board(next_state)[tf.newaxis,:])\n",
    "                if Qvalue>=best_value:\n",
    "                    best_value = Qvalue\n",
    "                    next_move = move\n",
    "        \n",
    "        action = (next_move//15,next_move%15)\n",
    "        self.env.board[action]=self.piece\n",
    "        next_state = self.env.get_state(self.env.board)\n",
    "        self.env.game_over()\n",
    "        reward = self.env.rewards(self)\n",
    "        self.replay_buffer.append((current_state,next_state,next_move,reward))\n",
    "    \n",
    "    def update_buffer(self):\n",
    "        if len(self.replay_buffer)>5000:\n",
    "            self.replay_buffer = self.replay_buffer[len(self.replay_buffer-5000)::] \n",
    "            \n",
    "    def prepare_batch(self,batchsize):\n",
    "        batch = np.random.choice(self.replay_buffer,batchsize,replace = False)\n",
    "        current_state = pd.Series(batch[:,0])\n",
    "        state_boards = current_state.apply(self.env.board)\n",
    "        # create vector masking the invalid moves dim = (batchsize,225)\n",
    "        masks = np.array(state_boards.apply(self.valid_mask))\n",
    "        # list of arrays representing the boards dim = (batchsize,15,15)\n",
    "        inputs = np.array(state_boards)\n",
    "        return (inputs,masks,rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QModel(Model):\n",
    "    def __init__(self,n_filters=16):\n",
    "        super (QModel,self).__init__()\n",
    "        self.conv1 = layers.Conv2D(n_filters,(5,5),strides = 1,padding = 'same',activation = 'relu')\n",
    "        self.conv2 = layers.Conv2D(n_filters*2,(5,5),strides = 1,padding = 'same',activation = 'relu')\n",
    "        self.flat = layers.Flatten()\n",
    "        self.final = layers.Dense(225,'tanh')\n",
    "        \n",
    "    def call(self,inputs,mask):\n",
    "        #inputs dim = (batchsize,15,15)\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.final(x)\n",
    "        #outputs dim = (batchsize,225)\n",
    "        if mask != None:\n",
    "            x+=mask*-1e2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qtarget = QModel()\n",
    "Qvalue = QModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(outputs,inputs,target_model,masks,rewards):\n",
    "    target = target_model(inputs,masks)\n",
    "    loss_mask = tf.math.logical_not(tf.math.less(outputs, -1))\n",
    "    loss_mask = tf.cast(loss_mask,'float32')\n",
    "    loss = outputs\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = tf.constant([[1,2,4],[-100,-100,2],[0,3,-1]])\n",
    "l=tf.cast(tf.math.logical_not(tf.math.less(n, -1)),'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=475, shape=(), dtype=float32, numpy=25.0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(25*l)/tf.cast(tf.math.count_nonzero(l),'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=482, shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(tf.math.count_nonzero(l),'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
