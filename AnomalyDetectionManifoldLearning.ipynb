{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers,Model,utils\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"rare_event_detection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>x52</th>\n",
       "      <th>x53</th>\n",
       "      <th>x54</th>\n",
       "      <th>x55</th>\n",
       "      <th>x56</th>\n",
       "      <th>x57</th>\n",
       "      <th>x58</th>\n",
       "      <th>x59</th>\n",
       "      <th>x60</th>\n",
       "      <th>x61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/99 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376665</td>\n",
       "      <td>-4.596435</td>\n",
       "      <td>-4.095756</td>\n",
       "      <td>13.497687</td>\n",
       "      <td>-0.118830</td>\n",
       "      <td>-20.669883</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.091721</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>-4.936434</td>\n",
       "      <td>-24.590146</td>\n",
       "      <td>18.515436</td>\n",
       "      <td>3.473400</td>\n",
       "      <td>0.033444</td>\n",
       "      <td>0.953219</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/1/99 0:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475720</td>\n",
       "      <td>-4.542502</td>\n",
       "      <td>-4.018359</td>\n",
       "      <td>16.230659</td>\n",
       "      <td>-0.128733</td>\n",
       "      <td>-18.758079</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.095871</td>\n",
       "      <td>0.062801</td>\n",
       "      <td>-4.937179</td>\n",
       "      <td>-32.413266</td>\n",
       "      <td>22.760065</td>\n",
       "      <td>2.682933</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>1.090502</td>\n",
       "      <td>0.006083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/1/99 0:04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363848</td>\n",
       "      <td>-4.681394</td>\n",
       "      <td>-4.353147</td>\n",
       "      <td>14.127998</td>\n",
       "      <td>-0.138636</td>\n",
       "      <td>-17.836632</td>\n",
       "      <td>0.010803</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.100265</td>\n",
       "      <td>0.072322</td>\n",
       "      <td>-4.937924</td>\n",
       "      <td>-34.183774</td>\n",
       "      <td>27.004663</td>\n",
       "      <td>3.537487</td>\n",
       "      <td>0.033629</td>\n",
       "      <td>1.840540</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/1/99 0:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.301590</td>\n",
       "      <td>-4.758934</td>\n",
       "      <td>-4.023612</td>\n",
       "      <td>13.161567</td>\n",
       "      <td>-0.148142</td>\n",
       "      <td>-18.517601</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.104660</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>-4.938669</td>\n",
       "      <td>-35.954281</td>\n",
       "      <td>21.672449</td>\n",
       "      <td>3.986095</td>\n",
       "      <td>0.033721</td>\n",
       "      <td>2.554880</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/99 0:08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265578</td>\n",
       "      <td>-4.749928</td>\n",
       "      <td>-4.333150</td>\n",
       "      <td>15.267340</td>\n",
       "      <td>-0.155314</td>\n",
       "      <td>-17.505913</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>...</td>\n",
       "      <td>10.109054</td>\n",
       "      <td>0.091121</td>\n",
       "      <td>-4.939414</td>\n",
       "      <td>-37.724789</td>\n",
       "      <td>21.907251</td>\n",
       "      <td>3.601573</td>\n",
       "      <td>0.033777</td>\n",
       "      <td>1.410494</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          time  y        x1        x2        x3         x4        x5  \\\n",
       "0  5/1/99 0:00  0  0.376665 -4.596435 -4.095756  13.497687 -0.118830   \n",
       "1  5/1/99 0:02  0  0.475720 -4.542502 -4.018359  16.230659 -0.128733   \n",
       "2  5/1/99 0:04  0  0.363848 -4.681394 -4.353147  14.127998 -0.138636   \n",
       "3  5/1/99 0:06  0  0.301590 -4.758934 -4.023612  13.161567 -0.148142   \n",
       "4  5/1/99 0:08  0  0.265578 -4.749928 -4.333150  15.267340 -0.155314   \n",
       "\n",
       "          x6        x7        x8  ...        x52       x53       x54  \\\n",
       "0 -20.669883  0.000732 -0.061114  ...  10.091721  0.053279 -4.936434   \n",
       "1 -18.758079  0.000732 -0.061114  ...  10.095871  0.062801 -4.937179   \n",
       "2 -17.836632  0.010803 -0.061114  ...  10.100265  0.072322 -4.937924   \n",
       "3 -18.517601  0.002075 -0.061114  ...  10.104660  0.081600 -4.938669   \n",
       "4 -17.505913  0.000732 -0.061114  ...  10.109054  0.091121 -4.939414   \n",
       "\n",
       "         x55        x56       x57       x58       x59       x60  x61  \n",
       "0 -24.590146  18.515436  3.473400  0.033444  0.953219  0.006076    0  \n",
       "1 -32.413266  22.760065  2.682933  0.033536  1.090502  0.006083    0  \n",
       "2 -34.183774  27.004663  3.537487  0.033629  1.840540  0.006090    0  \n",
       "3 -35.954281  21.672449  3.986095  0.033721  2.554880  0.006097    0  \n",
       "4 -37.724789  21.907251  3.601573  0.033777  1.410494  0.006105    0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x52</th>\n",
       "      <th>x53</th>\n",
       "      <th>x54</th>\n",
       "      <th>x55</th>\n",
       "      <th>x56</th>\n",
       "      <th>x57</th>\n",
       "      <th>x58</th>\n",
       "      <th>x59</th>\n",
       "      <th>x60</th>\n",
       "      <th>x61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "      <td>18398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>0.157986</td>\n",
       "      <td>0.569300</td>\n",
       "      <td>-9.958345</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>2.387533</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>-0.004125</td>\n",
       "      <td>-0.003056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380519</td>\n",
       "      <td>0.360246</td>\n",
       "      <td>0.173708</td>\n",
       "      <td>2.379154</td>\n",
       "      <td>9.234953</td>\n",
       "      <td>0.233493</td>\n",
       "      <td>-0.001861</td>\n",
       "      <td>-0.061522</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.081822</td>\n",
       "      <td>0.742875</td>\n",
       "      <td>4.939762</td>\n",
       "      <td>5.937178</td>\n",
       "      <td>131.033712</td>\n",
       "      <td>0.634054</td>\n",
       "      <td>37.104012</td>\n",
       "      <td>0.108870</td>\n",
       "      <td>0.075460</td>\n",
       "      <td>0.156047</td>\n",
       "      <td>...</td>\n",
       "      <td>6.211598</td>\n",
       "      <td>14.174273</td>\n",
       "      <td>3.029516</td>\n",
       "      <td>67.940694</td>\n",
       "      <td>81.274103</td>\n",
       "      <td>2.326838</td>\n",
       "      <td>0.048732</td>\n",
       "      <td>10.394085</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.032120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.787279</td>\n",
       "      <td>-17.316550</td>\n",
       "      <td>-18.198509</td>\n",
       "      <td>-322.781610</td>\n",
       "      <td>-1.623988</td>\n",
       "      <td>-279.408440</td>\n",
       "      <td>-0.429273</td>\n",
       "      <td>-0.451141</td>\n",
       "      <td>-0.120087</td>\n",
       "      <td>...</td>\n",
       "      <td>-187.943440</td>\n",
       "      <td>-1817.595500</td>\n",
       "      <td>-8.210370</td>\n",
       "      <td>-230.574030</td>\n",
       "      <td>-269.039500</td>\n",
       "      <td>-12.640370</td>\n",
       "      <td>-0.149790</td>\n",
       "      <td>-100.810500</td>\n",
       "      <td>-0.012229</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.405681</td>\n",
       "      <td>-2.158235</td>\n",
       "      <td>-3.537054</td>\n",
       "      <td>-111.378372</td>\n",
       "      <td>-0.446787</td>\n",
       "      <td>-24.345268</td>\n",
       "      <td>-0.058520</td>\n",
       "      <td>-0.051043</td>\n",
       "      <td>-0.059966</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.672684</td>\n",
       "      <td>-1.928166</td>\n",
       "      <td>0.487780</td>\n",
       "      <td>-40.050046</td>\n",
       "      <td>-45.519149</td>\n",
       "      <td>-1.598804</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.295023</td>\n",
       "      <td>-0.001805</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128245</td>\n",
       "      <td>-0.075505</td>\n",
       "      <td>-0.190683</td>\n",
       "      <td>-14.881585</td>\n",
       "      <td>-0.120745</td>\n",
       "      <td>10.528435</td>\n",
       "      <td>-0.009339</td>\n",
       "      <td>-0.000993</td>\n",
       "      <td>-0.030057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294846</td>\n",
       "      <td>0.143612</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>17.471317</td>\n",
       "      <td>1.438806</td>\n",
       "      <td>0.085826</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>0.734591</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421222</td>\n",
       "      <td>2.319297</td>\n",
       "      <td>3.421223</td>\n",
       "      <td>92.199134</td>\n",
       "      <td>0.325152</td>\n",
       "      <td>32.172974</td>\n",
       "      <td>0.060515</td>\n",
       "      <td>0.038986</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>...</td>\n",
       "      <td>5.109543</td>\n",
       "      <td>3.230770</td>\n",
       "      <td>2.675751</td>\n",
       "      <td>44.093387</td>\n",
       "      <td>63.209681</td>\n",
       "      <td>2.222118</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>1.266506</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.054156</td>\n",
       "      <td>16.742105</td>\n",
       "      <td>15.900116</td>\n",
       "      <td>334.694098</td>\n",
       "      <td>4.239385</td>\n",
       "      <td>96.060768</td>\n",
       "      <td>1.705590</td>\n",
       "      <td>0.788826</td>\n",
       "      <td>4.060033</td>\n",
       "      <td>...</td>\n",
       "      <td>14.180588</td>\n",
       "      <td>11.148006</td>\n",
       "      <td>6.637265</td>\n",
       "      <td>287.252017</td>\n",
       "      <td>252.147455</td>\n",
       "      <td>6.922008</td>\n",
       "      <td>0.067249</td>\n",
       "      <td>6.985460</td>\n",
       "      <td>0.020510</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  y            x1            x2            x3            x4  \\\n",
       "count  18398.000000  18398.000000  18398.000000  18398.000000  18398.000000   \n",
       "mean       0.006740      0.011824      0.157986      0.569300     -9.958345   \n",
       "std        0.081822      0.742875      4.939762      5.937178    131.033712   \n",
       "min        0.000000     -3.787279    -17.316550    -18.198509   -322.781610   \n",
       "25%        0.000000     -0.405681     -2.158235     -3.537054   -111.378372   \n",
       "50%        0.000000      0.128245     -0.075505     -0.190683    -14.881585   \n",
       "75%        0.000000      0.421222      2.319297      3.421223     92.199134   \n",
       "max        1.000000      3.054156     16.742105     15.900116    334.694098   \n",
       "\n",
       "                 x5            x6            x7            x8            x9  \\\n",
       "count  18398.000000  18398.000000  18398.000000  18398.000000  18398.000000   \n",
       "mean       0.006518      2.387533      0.001647     -0.004125     -0.003056   \n",
       "std        0.634054     37.104012      0.108870      0.075460      0.156047   \n",
       "min       -1.623988   -279.408440     -0.429273     -0.451141     -0.120087   \n",
       "25%       -0.446787    -24.345268     -0.058520     -0.051043     -0.059966   \n",
       "50%       -0.120745     10.528435     -0.009339     -0.000993     -0.030057   \n",
       "75%        0.325152     32.172974      0.060515      0.038986      0.001990   \n",
       "max        4.239385     96.060768      1.705590      0.788826      4.060033   \n",
       "\n",
       "       ...           x52           x53           x54           x55  \\\n",
       "count  ...  18398.000000  18398.000000  18398.000000  18398.000000   \n",
       "mean   ...      0.380519      0.360246      0.173708      2.379154   \n",
       "std    ...      6.211598     14.174273      3.029516     67.940694   \n",
       "min    ...   -187.943440  -1817.595500     -8.210370   -230.574030   \n",
       "25%    ...     -3.672684     -1.928166      0.487780    -40.050046   \n",
       "50%    ...      0.294846      0.143612      0.702299     17.471317   \n",
       "75%    ...      5.109543      3.230770      2.675751     44.093387   \n",
       "max    ...     14.180588     11.148006      6.637265    287.252017   \n",
       "\n",
       "                x56           x57           x58           x59           x60  \\\n",
       "count  18398.000000  18398.000000  18398.000000  18398.000000  18398.000000   \n",
       "mean       9.234953      0.233493     -0.001861     -0.061522      0.001258   \n",
       "std       81.274103      2.326838      0.048732     10.394085      0.004721   \n",
       "min     -269.039500    -12.640370     -0.149790   -100.810500     -0.012229   \n",
       "25%      -45.519149     -1.598804      0.000470      0.295023     -0.001805   \n",
       "50%        1.438806      0.085826      0.012888      0.734591      0.000710   \n",
       "75%       63.209681      2.222118      0.020991      1.266506      0.004087   \n",
       "max      252.147455      6.922008      0.067249      6.985460      0.020510   \n",
       "\n",
       "                x61  \n",
       "count  18398.000000  \n",
       "mean       0.001033  \n",
       "std        0.032120  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18274\n",
       "1      124\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that given 124 anomalies out of 18398 samples, the event that we are trying to detect is very rare ~0.674%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the original paper, the features/columns of the dataset represents continous instrumentation data, likely analog force signals measured via loadcells, accelerometers, encoders, drive current loads etc. While x28 is categorical and x61 is binary. In the next few cells we will separate the continuous and categorical features in order to encode them more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ContinuousData = data.iloc[:,2:-1].drop(columns = [\"x28\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rates of change overtime of the features are likely to contribute more to the web breaks and failures that we are trying to detect. In order to capture that information we'll compute the rates of change via the first order difference and concatenate them as features to our existing dataset.\n",
    "\n",
    "A general rule of thumb is that for complex feature sets, where the features are not independent of eachother and redundancies may exist, the number of samples $N$ in the dataset must be larger than $\\sqrt{N}$ in order to avoid the \"curse of dimensionality\". The addition of first-order derivatives for the continuous features will take us to 120 features, and $120^2=14400 < 18274$. So we can cautiously conclude that we have enough data to avoid needing too many parameters in our model and risking overfitting. (we actually have 127 features after we one-hot encode the categorical data, but we're still ok)\n",
    "\n",
    "First order central difference is given by:\n",
    "\\begin{align}\n",
    "\\\\\n",
    "f'(x) \\approx \\frac{f(x+\\frac{1}{2}h)-f(x-\\frac{1}{2}h)}{h}\\\\\n",
    "\\end{align}\n",
    "\n",
    "Central difference is used since it has the most accurate approximation. The $h$ we will use is 4 mins.\n",
    "It is also convenient to ensure that the indexing of the data doesn't change regardless of the fact that the derivatives can't be computed for the first and last terms in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FirstOrderCentralDifference(data):\n",
    "    data_backward = np.array(data.copy().iloc[:-2,:])\n",
    "    data_forward = np.array(data.copy().iloc[2::,:])\n",
    "    \n",
    "    first_order_features = (data_forward-data_backward)/4.0\n",
    "    old_names = data.columns.values.tolist()\n",
    "    new_names = [('d'+name) for name in old_names]\n",
    "    first_order_features = pd.DataFrame(first_order_features,index = range(1,18397), columns = new_names)\n",
    "    \n",
    "    return pd.concat([data.drop([0,18397]),first_order_features],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataNewFeatures = FirstOrderCentralDifference(ContinuousData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>dx51</th>\n",
       "      <th>dx52</th>\n",
       "      <th>dx53</th>\n",
       "      <th>dx54</th>\n",
       "      <th>dx55</th>\n",
       "      <th>dx56</th>\n",
       "      <th>dx57</th>\n",
       "      <th>dx58</th>\n",
       "      <th>dx59</th>\n",
       "      <th>dx60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.475720</td>\n",
       "      <td>-4.542502</td>\n",
       "      <td>-4.018359</td>\n",
       "      <td>16.230659</td>\n",
       "      <td>-0.128733</td>\n",
       "      <td>-18.758079</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>-0.059966</td>\n",
       "      <td>-0.038189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>-2.398407</td>\n",
       "      <td>2.122307</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.221830</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.363848</td>\n",
       "      <td>-4.681394</td>\n",
       "      <td>-4.353147</td>\n",
       "      <td>14.127998</td>\n",
       "      <td>-0.138636</td>\n",
       "      <td>-17.836632</td>\n",
       "      <td>0.010803</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>-0.030057</td>\n",
       "      <td>-0.018352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>-0.885254</td>\n",
       "      <td>-0.271904</td>\n",
       "      <td>0.325790</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.366094</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.301590</td>\n",
       "      <td>-4.758934</td>\n",
       "      <td>-4.023612</td>\n",
       "      <td>13.161567</td>\n",
       "      <td>-0.148142</td>\n",
       "      <td>-18.517601</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>-0.019986</td>\n",
       "      <td>-0.008280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>-0.000372</td>\n",
       "      <td>-0.885254</td>\n",
       "      <td>-1.274353</td>\n",
       "      <td>0.016022</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.107511</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265578</td>\n",
       "      <td>-4.749928</td>\n",
       "      <td>-4.333150</td>\n",
       "      <td>15.267340</td>\n",
       "      <td>-0.155314</td>\n",
       "      <td>-17.505913</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>-0.030057</td>\n",
       "      <td>-0.008280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>-0.068024</td>\n",
       "      <td>0.410110</td>\n",
       "      <td>-0.080109</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.417061</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.381253</td>\n",
       "      <td>-4.611746</td>\n",
       "      <td>-4.085072</td>\n",
       "      <td>14.143195</td>\n",
       "      <td>-0.162501</td>\n",
       "      <td>-16.494255</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>-0.030057</td>\n",
       "      <td>-0.008280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>-0.000372</td>\n",
       "      <td>1.374176</td>\n",
       "      <td>0.702812</td>\n",
       "      <td>0.128174</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.021938</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18392</th>\n",
       "      <td>-0.863607</td>\n",
       "      <td>0.735248</td>\n",
       "      <td>0.266091</td>\n",
       "      <td>133.555731</td>\n",
       "      <td>0.083242</td>\n",
       "      <td>26.922188</td>\n",
       "      <td>-0.139347</td>\n",
       "      <td>0.058823</td>\n",
       "      <td>-0.080108</td>\n",
       "      <td>-0.038189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.331757</td>\n",
       "      <td>0.407589</td>\n",
       "      <td>-0.160218</td>\n",
       "      <td>-0.000384</td>\n",
       "      <td>0.136722</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18393</th>\n",
       "      <td>-0.877442</td>\n",
       "      <td>0.786430</td>\n",
       "      <td>0.406426</td>\n",
       "      <td>135.301215</td>\n",
       "      <td>0.112295</td>\n",
       "      <td>26.300392</td>\n",
       "      <td>-0.159185</td>\n",
       "      <td>0.058823</td>\n",
       "      <td>-0.080108</td>\n",
       "      <td>-0.038189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>-3.560700</td>\n",
       "      <td>-0.987248</td>\n",
       "      <td>0.138733</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>-0.223778</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18394</th>\n",
       "      <td>-0.843988</td>\n",
       "      <td>0.633086</td>\n",
       "      <td>0.561918</td>\n",
       "      <td>133.228949</td>\n",
       "      <td>0.141332</td>\n",
       "      <td>25.678597</td>\n",
       "      <td>-0.159185</td>\n",
       "      <td>0.058823</td>\n",
       "      <td>-0.080108</td>\n",
       "      <td>-0.038189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>-1.033875</td>\n",
       "      <td>-0.390385</td>\n",
       "      <td>-0.137344</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>-0.068666</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18395</th>\n",
       "      <td>-0.826547</td>\n",
       "      <td>0.450126</td>\n",
       "      <td>0.334582</td>\n",
       "      <td>134.977973</td>\n",
       "      <td>0.170370</td>\n",
       "      <td>25.056801</td>\n",
       "      <td>-0.159185</td>\n",
       "      <td>0.048752</td>\n",
       "      <td>-0.080108</td>\n",
       "      <td>-0.038189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.414276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.303889</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18396</th>\n",
       "      <td>-0.822842</td>\n",
       "      <td>0.419383</td>\n",
       "      <td>0.387263</td>\n",
       "      <td>135.658942</td>\n",
       "      <td>0.199422</td>\n",
       "      <td>24.435005</td>\n",
       "      <td>-0.159185</td>\n",
       "      <td>0.048752</td>\n",
       "      <td>-0.080108</td>\n",
       "      <td>-0.038189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>-0.348114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169388</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.050507</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18396 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        x2        x3          x4        x5         x6  \\\n",
       "1      0.475720 -4.542502 -4.018359   16.230659 -0.128733 -18.758079   \n",
       "2      0.363848 -4.681394 -4.353147   14.127998 -0.138636 -17.836632   \n",
       "3      0.301590 -4.758934 -4.023612   13.161567 -0.148142 -18.517601   \n",
       "4      0.265578 -4.749928 -4.333150   15.267340 -0.155314 -17.505913   \n",
       "5      0.381253 -4.611746 -4.085072   14.143195 -0.162501 -16.494255   \n",
       "...         ...       ...       ...         ...       ...        ...   \n",
       "18392 -0.863607  0.735248  0.266091  133.555731  0.083242  26.922188   \n",
       "18393 -0.877442  0.786430  0.406426  135.301215  0.112295  26.300392   \n",
       "18394 -0.843988  0.633086  0.561918  133.228949  0.141332  25.678597   \n",
       "18395 -0.826547  0.450126  0.334582  134.977973  0.170370  25.056801   \n",
       "18396 -0.822842  0.419383  0.387263  135.658942  0.199422  24.435005   \n",
       "\n",
       "             x7        x8        x9       x10  ...  dx51      dx52      dx53  \\\n",
       "1      0.000732 -0.061114 -0.059966 -0.038189  ...   0.0  0.002136  0.004761   \n",
       "2      0.010803 -0.061114 -0.030057 -0.018352  ...   0.0  0.002197  0.004700   \n",
       "3      0.002075 -0.061114 -0.019986 -0.008280  ...   0.0  0.002197  0.004700   \n",
       "4      0.000732 -0.061114 -0.030057 -0.008280  ...   0.0  0.002197  0.004761   \n",
       "5      0.000732 -0.061114 -0.030057 -0.008280  ...   0.0  0.002197  0.004700   \n",
       "...         ...       ...       ...       ...  ...   ...       ...       ...   \n",
       "18392 -0.139347  0.058823 -0.080108 -0.038189  ...   0.0  0.000000  0.000000   \n",
       "18393 -0.159185  0.058823 -0.080108 -0.038189  ...   0.0  0.000000  0.000000   \n",
       "18394 -0.159185  0.058823 -0.080108 -0.038189  ...   0.0  0.000000  0.000000   \n",
       "18395 -0.159185  0.048752 -0.080108 -0.038189  ...   0.0  0.000000  0.000000   \n",
       "18396 -0.159185  0.048752 -0.080108 -0.038189  ...   0.0  0.000000  0.000000   \n",
       "\n",
       "           dx54      dx55      dx56      dx57      dx58      dx59      dx60  \n",
       "1     -0.000373 -2.398407  2.122307  0.016022  0.000046  0.221830  0.000004  \n",
       "2     -0.000373 -0.885254 -0.271904  0.325790  0.000046  0.366094  0.000004  \n",
       "3     -0.000372 -0.885254 -1.274353  0.016022  0.000037 -0.107511  0.000004  \n",
       "4     -0.000373 -0.068024  0.410110 -0.080109 -0.000024 -0.417061  0.000004  \n",
       "5     -0.000372  1.374176  0.702812  0.128174 -0.000076 -0.021938  0.000004  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "18392  0.000462  0.331757  0.407589 -0.160218 -0.000384  0.136722  0.000004  \n",
       "18393  0.000463 -3.560700 -0.987248  0.138733  0.000200 -0.223778  0.000004  \n",
       "18394  0.000463 -1.033875 -0.390385 -0.137344  0.000776 -0.068666  0.000004  \n",
       "18395  0.000463  0.414276  0.000000  0.013870  0.000567  0.303889  0.000004  \n",
       "18396  0.000463 -0.348114  0.000000  0.169388 -0.000217 -0.050507  0.000004  \n",
       "\n",
       "[18396 rows x 118 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataNewFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we identify the indices of the anomalies (where y=1), and time shift it by 2 mins by shifting the indices back by 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([0,18397],inplace = True)\n",
    "y = data.y\n",
    "anomalies = y[y==1].index.copy()-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the standard scaler from sklearn to fit the continuous dataset without the anomalies, we will then use this scaler to transform the dataset before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(DataNewFeatures.drop(anomalies))\n",
    "DataNewFeatures.iloc[:,:] = scaler.transform(DataNewFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we take the categorical data x28 and apply one-hot encoding, and re-concatenate the categorical/binary data back onto the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca =PCA(n_components=40)\n",
    "pca.fit(DataNewFeatures.drop(anomalies))\n",
    "CompressedData = pd.DataFrame(pca.transform(DataNewFeatures),columns = ['pca_'+str(i) for i in range(1,41)],index = DataNewFeatures.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>pca_6</th>\n",
       "      <th>pca_7</th>\n",
       "      <th>pca_8</th>\n",
       "      <th>pca_9</th>\n",
       "      <th>pca_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_31</th>\n",
       "      <th>pca_32</th>\n",
       "      <th>pca_33</th>\n",
       "      <th>pca_34</th>\n",
       "      <th>pca_35</th>\n",
       "      <th>pca_36</th>\n",
       "      <th>pca_37</th>\n",
       "      <th>pca_38</th>\n",
       "      <th>pca_39</th>\n",
       "      <th>pca_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.167629</td>\n",
       "      <td>2.600992</td>\n",
       "      <td>-3.226726</td>\n",
       "      <td>1.756410</td>\n",
       "      <td>0.285215</td>\n",
       "      <td>-1.979060</td>\n",
       "      <td>-0.302861</td>\n",
       "      <td>-2.039335</td>\n",
       "      <td>1.108804</td>\n",
       "      <td>0.674263</td>\n",
       "      <td>...</td>\n",
       "      <td>1.108835</td>\n",
       "      <td>-0.555957</td>\n",
       "      <td>1.074870</td>\n",
       "      <td>0.123503</td>\n",
       "      <td>0.107997</td>\n",
       "      <td>0.410309</td>\n",
       "      <td>-0.381550</td>\n",
       "      <td>0.074467</td>\n",
       "      <td>0.201801</td>\n",
       "      <td>-0.036035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014362</td>\n",
       "      <td>2.742412</td>\n",
       "      <td>-3.392821</td>\n",
       "      <td>1.572466</td>\n",
       "      <td>-0.508394</td>\n",
       "      <td>-2.034387</td>\n",
       "      <td>0.481219</td>\n",
       "      <td>-1.746487</td>\n",
       "      <td>1.159130</td>\n",
       "      <td>0.420975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472299</td>\n",
       "      <td>-0.231584</td>\n",
       "      <td>0.038839</td>\n",
       "      <td>0.547102</td>\n",
       "      <td>-0.785782</td>\n",
       "      <td>0.213005</td>\n",
       "      <td>0.038063</td>\n",
       "      <td>-0.300213</td>\n",
       "      <td>-0.216029</td>\n",
       "      <td>0.251879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.071939</td>\n",
       "      <td>2.845502</td>\n",
       "      <td>-3.590585</td>\n",
       "      <td>1.751223</td>\n",
       "      <td>-0.783989</td>\n",
       "      <td>-1.971114</td>\n",
       "      <td>0.558302</td>\n",
       "      <td>-1.770162</td>\n",
       "      <td>0.733995</td>\n",
       "      <td>-0.028564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546846</td>\n",
       "      <td>0.499526</td>\n",
       "      <td>-0.246412</td>\n",
       "      <td>0.303263</td>\n",
       "      <td>-0.451376</td>\n",
       "      <td>1.035091</td>\n",
       "      <td>0.091831</td>\n",
       "      <td>-0.757311</td>\n",
       "      <td>-0.292343</td>\n",
       "      <td>0.191398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004690</td>\n",
       "      <td>2.868573</td>\n",
       "      <td>-3.472332</td>\n",
       "      <td>1.838236</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>-1.859913</td>\n",
       "      <td>0.093673</td>\n",
       "      <td>-2.026191</td>\n",
       "      <td>0.842123</td>\n",
       "      <td>0.118747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313379</td>\n",
       "      <td>-0.238419</td>\n",
       "      <td>-0.196143</td>\n",
       "      <td>-2.062854</td>\n",
       "      <td>0.766608</td>\n",
       "      <td>-0.627388</td>\n",
       "      <td>0.273081</td>\n",
       "      <td>1.645788</td>\n",
       "      <td>0.913342</td>\n",
       "      <td>-0.248585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.230351</td>\n",
       "      <td>2.727784</td>\n",
       "      <td>-3.105792</td>\n",
       "      <td>1.796392</td>\n",
       "      <td>0.057416</td>\n",
       "      <td>-2.176919</td>\n",
       "      <td>0.089314</td>\n",
       "      <td>-1.703034</td>\n",
       "      <td>0.804679</td>\n",
       "      <td>0.116652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513857</td>\n",
       "      <td>-0.294346</td>\n",
       "      <td>-0.862000</td>\n",
       "      <td>-1.701495</td>\n",
       "      <td>0.373503</td>\n",
       "      <td>-1.397144</td>\n",
       "      <td>0.699209</td>\n",
       "      <td>1.516030</td>\n",
       "      <td>0.668368</td>\n",
       "      <td>-0.059836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18392</th>\n",
       "      <td>-0.136244</td>\n",
       "      <td>-1.177658</td>\n",
       "      <td>2.352382</td>\n",
       "      <td>-0.825703</td>\n",
       "      <td>0.306900</td>\n",
       "      <td>-0.572332</td>\n",
       "      <td>-1.183953</td>\n",
       "      <td>1.875732</td>\n",
       "      <td>0.489718</td>\n",
       "      <td>0.044276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553209</td>\n",
       "      <td>-0.199925</td>\n",
       "      <td>-0.133705</td>\n",
       "      <td>1.399495</td>\n",
       "      <td>-1.325788</td>\n",
       "      <td>0.471069</td>\n",
       "      <td>0.409817</td>\n",
       "      <td>-0.024403</td>\n",
       "      <td>0.350956</td>\n",
       "      <td>0.919677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18393</th>\n",
       "      <td>-0.054324</td>\n",
       "      <td>-1.098553</td>\n",
       "      <td>2.099753</td>\n",
       "      <td>-0.939694</td>\n",
       "      <td>-0.460712</td>\n",
       "      <td>-0.551583</td>\n",
       "      <td>-1.245453</td>\n",
       "      <td>1.717678</td>\n",
       "      <td>0.541541</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.338933</td>\n",
       "      <td>0.183444</td>\n",
       "      <td>-1.126548</td>\n",
       "      <td>0.696736</td>\n",
       "      <td>-2.039637</td>\n",
       "      <td>1.121893</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>-0.784339</td>\n",
       "      <td>-0.414185</td>\n",
       "      <td>0.271455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18394</th>\n",
       "      <td>-0.171016</td>\n",
       "      <td>-1.021021</td>\n",
       "      <td>2.079271</td>\n",
       "      <td>-0.771285</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>-0.447430</td>\n",
       "      <td>-1.421399</td>\n",
       "      <td>1.679614</td>\n",
       "      <td>0.596861</td>\n",
       "      <td>0.153515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654759</td>\n",
       "      <td>0.363424</td>\n",
       "      <td>-1.471016</td>\n",
       "      <td>-1.514263</td>\n",
       "      <td>-0.227849</td>\n",
       "      <td>0.107614</td>\n",
       "      <td>0.993270</td>\n",
       "      <td>0.289769</td>\n",
       "      <td>-0.097619</td>\n",
       "      <td>-0.209047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18395</th>\n",
       "      <td>-0.045102</td>\n",
       "      <td>-1.130353</td>\n",
       "      <td>2.366625</td>\n",
       "      <td>-0.624002</td>\n",
       "      <td>0.413195</td>\n",
       "      <td>-0.621286</td>\n",
       "      <td>-1.085347</td>\n",
       "      <td>1.973136</td>\n",
       "      <td>0.694115</td>\n",
       "      <td>-0.152921</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.202913</td>\n",
       "      <td>0.101659</td>\n",
       "      <td>-1.211454</td>\n",
       "      <td>-1.644417</td>\n",
       "      <td>-0.406601</td>\n",
       "      <td>-0.218974</td>\n",
       "      <td>0.993431</td>\n",
       "      <td>0.397249</td>\n",
       "      <td>0.293525</td>\n",
       "      <td>-0.387625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18396</th>\n",
       "      <td>0.014856</td>\n",
       "      <td>-1.126658</td>\n",
       "      <td>2.168725</td>\n",
       "      <td>-0.664781</td>\n",
       "      <td>0.016431</td>\n",
       "      <td>-0.622891</td>\n",
       "      <td>-0.953734</td>\n",
       "      <td>1.961903</td>\n",
       "      <td>0.533699</td>\n",
       "      <td>-0.184207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.331765</td>\n",
       "      <td>-0.301234</td>\n",
       "      <td>-0.638905</td>\n",
       "      <td>0.190146</td>\n",
       "      <td>-0.547642</td>\n",
       "      <td>1.157846</td>\n",
       "      <td>-0.130978</td>\n",
       "      <td>-0.404107</td>\n",
       "      <td>0.145694</td>\n",
       "      <td>0.321255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18396 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pca_1     pca_2     pca_3     pca_4     pca_5     pca_6     pca_7  \\\n",
       "1      0.167629  2.600992 -3.226726  1.756410  0.285215 -1.979060 -0.302861   \n",
       "2      0.014362  2.742412 -3.392821  1.572466 -0.508394 -2.034387  0.481219   \n",
       "3     -0.071939  2.845502 -3.590585  1.751223 -0.783989 -1.971114  0.558302   \n",
       "4      0.004690  2.868573 -3.472332  1.838236  0.003952 -1.859913  0.093673   \n",
       "5      0.230351  2.727784 -3.105792  1.796392  0.057416 -2.176919  0.089314   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "18392 -0.136244 -1.177658  2.352382 -0.825703  0.306900 -0.572332 -1.183953   \n",
       "18393 -0.054324 -1.098553  2.099753 -0.939694 -0.460712 -0.551583 -1.245453   \n",
       "18394 -0.171016 -1.021021  2.079271 -0.771285  0.012393 -0.447430 -1.421399   \n",
       "18395 -0.045102 -1.130353  2.366625 -0.624002  0.413195 -0.621286 -1.085347   \n",
       "18396  0.014856 -1.126658  2.168725 -0.664781  0.016431 -0.622891 -0.953734   \n",
       "\n",
       "          pca_8     pca_9    pca_10  ...    pca_31    pca_32    pca_33  \\\n",
       "1     -2.039335  1.108804  0.674263  ...  1.108835 -0.555957  1.074870   \n",
       "2     -1.746487  1.159130  0.420975  ...  0.472299 -0.231584  0.038839   \n",
       "3     -1.770162  0.733995 -0.028564  ... -0.546846  0.499526 -0.246412   \n",
       "4     -2.026191  0.842123  0.118747  ... -0.313379 -0.238419 -0.196143   \n",
       "5     -1.703034  0.804679  0.116652  ... -0.513857 -0.294346 -0.862000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "18392  1.875732  0.489718  0.044276  ...  0.553209 -0.199925 -0.133705   \n",
       "18393  1.717678  0.541541  0.008198  ... -1.338933  0.183444 -1.126548   \n",
       "18394  1.679614  0.596861  0.153515  ... -0.654759  0.363424 -1.471016   \n",
       "18395  1.973136  0.694115 -0.152921  ... -1.202913  0.101659 -1.211454   \n",
       "18396  1.961903  0.533699 -0.184207  ... -0.331765 -0.301234 -0.638905   \n",
       "\n",
       "         pca_34    pca_35    pca_36    pca_37    pca_38    pca_39    pca_40  \n",
       "1      0.123503  0.107997  0.410309 -0.381550  0.074467  0.201801 -0.036035  \n",
       "2      0.547102 -0.785782  0.213005  0.038063 -0.300213 -0.216029  0.251879  \n",
       "3      0.303263 -0.451376  1.035091  0.091831 -0.757311 -0.292343  0.191398  \n",
       "4     -2.062854  0.766608 -0.627388  0.273081  1.645788  0.913342 -0.248585  \n",
       "5     -1.701495  0.373503 -1.397144  0.699209  1.516030  0.668368 -0.059836  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "18392  1.399495 -1.325788  0.471069  0.409817 -0.024403  0.350956  0.919677  \n",
       "18393  0.696736 -2.039637  1.121893 -0.000316 -0.784339 -0.414185  0.271455  \n",
       "18394 -1.514263 -0.227849  0.107614  0.993270  0.289769 -0.097619 -0.209047  \n",
       "18395 -1.644417 -0.406601 -0.218974  0.993431  0.397249  0.293525 -0.387625  \n",
       "18396  0.190146 -0.547642  1.157846 -0.130978 -0.404107  0.145694  0.321255  \n",
       "\n",
       "[18396 rows x 40 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompressedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x28 = pd.get_dummies(data.x28)\n",
    "x28 = x28.rename(columns = dict(zip(x28.columns.values.tolist(),[('x28_'+str(name)) for name in x28.columns.values.tolist()])))\n",
    "CompressedData = pd.concat([CompressedData,x28,data.x61],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we divide the dataframe into the training data and anomalous data, since we won't be using the anomalous data in the training set. Thus taking advantage of the fact that neural network models can't extrapolate very effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CompressedData.drop(anomalies)\n",
    "anomalous_data = CompressedData.iloc[anomalies-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preprocess the data we need to ensure that all sequences that would include the anomalies are removed, then we divide the dataset into sequences and return it as a np array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessData(data,seq_len=15):\n",
    "    dataset = np.array(data,'float32')\n",
    "    s = set(range(0,len(data)-seq_len))\n",
    "    for i in anomalies:\n",
    "        s.difference_update(set(range(i-seq_len+1,i+1)))\n",
    "    sequences = []\n",
    "    for i in list(s):\n",
    "        sequences.append(dataset[i:i+seq_len])\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the dataset will ultimately be (samples,sequence length, feature length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16581, 15, 49)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = PreprocessData(training_data)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (100, 15, 49), types: tf.float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset = tf.data.Dataset.from_tensor_slices(dataset).shuffle(1000).batch(100,drop_remainder=True)\n",
    "batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3 # kernel size\n",
    "latent_dim = 256 # dimension of the latent z\n",
    "n_filters=128 # initial filter depth for encoder\n",
    "depth = 3 # depth of dialated TCN\n",
    "seq_len = 15 # length of the time sequence\n",
    "feature_dim = 49 # feature dimension for input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self,k,latent_dim,n_filters,depth):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.depth = depth\n",
    "        \n",
    "        self.tcn_block =[\n",
    "                        layers.Conv1D(n_filters*2**(i),kernel_size = k,strides = 1, \n",
    "                        padding = 'causal',dilation_rate = 2**i,activation = 'elu')\n",
    "                        for i in range(depth)\n",
    "                        ]\n",
    "        \n",
    "        self.dropouts = [layers.Dropout(0.3) for i in range(depth)]\n",
    "        self.flat = layers.Flatten()\n",
    "        self.dense = layers.Dense(latent_dim*2)\n",
    "        \n",
    "        \n",
    "    def call(self,inputs,training = True):\n",
    "        # input dim = (100,15,49)\n",
    "        x = inputs\n",
    "        for i in range(self.depth):\n",
    "            x = self.tcn_block[i](x)\n",
    "            x = self.dropouts[i](x,training = training) \n",
    "        # dim = (100,15,512)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense(x)\n",
    "        # output dim = (100,512)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self,k,latent_dim,n_filters,depth,seq_len,feature_dim):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.depth = depth\n",
    "        self.dense1 = layers.Dense(seq_len*n_filters*2**(depth-1),activation = 'elu')\n",
    "        self.reshape = layers.Reshape((seq_len,n_filters*2**(depth-1)))\n",
    "        self.conv_layers =  [\n",
    "                            layers.Conv1D(n_filters*2**(depth-1-i),\n",
    "                            kernel_size = k, strides=1, padding = 'SAME', activation = 'elu')\n",
    "                            for i in range(depth)\n",
    "                            ]\n",
    "        self.dropouts = [layers.Dropout(0.3) for i in range(depth)]\n",
    "        self.generated_sequence = layers.Conv1D(feature_dim, kernel_size = k, strides = 1, padding = 'SAME')\n",
    "\n",
    "    def call(self,x,training = True):\n",
    "        # input dim = (100,256)\n",
    "        x = self.dense1(x)\n",
    "        # dim = (100,15*256)\n",
    "        x = self.reshape(x)\n",
    "        # dim = (100,15,256)\n",
    "        for i in range(self.depth):\n",
    "            x = self.conv_layers[i](x)\n",
    "            x = self.dropouts[i](x,training = training)\n",
    "        # dim = (100,15,128)\n",
    "        x = self.generated_sequence(x)\n",
    "        # output dim = (100,15,49)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reparameterize(mean,logvar,noise):\n",
    "    z=noise*tf.exp(logvar * 0.5)+mean\n",
    "    return z\n",
    "\n",
    "def logPDF(mean,logvar,z):\n",
    "    logf = -0.5*((z-mean)**2/(tf.math.exp(logvar)+1e-8)+tf.math.log(2*np.pi))\n",
    "    return logf\n",
    "\n",
    "def LossFunction(z,mean,logvar,generated_sequence,input_sequence,beta=0.3):\n",
    "    logpz = tf.reduce_sum(logPDF(0.0,0.0,z),axis = -1)\n",
    "    logqz = tf.reduce_sum(logPDF(mean,logvar,z),axis = -1)\n",
    "    logpxz = tf.reduce_sum(tf.keras.losses.MSE(input_sequence,generated_sequence))\n",
    "    \n",
    "    total_loss = beta*tf.reduce_mean(-logpz+logqz-logpxz)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BVAE(Model):\n",
    "    def __init__(self,k,latent_dim,n_filters,depth,seq_len,feature_dim):\n",
    "        super(BVAE,self).__init__()\n",
    "        self.encoder = Encoder(k,latent_dim,n_filters,depth)\n",
    "        self.decoder = Decoder(k,latent_dim,n_filters,depth,seq_len,feature_dim)\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def call(self,input_sequence,training = True):\n",
    "        x = self.encoder(input_sequence)\n",
    "        mean = x[:,:self.latent_dim]\n",
    "        logvar = x[:,self.latent_dim::]\n",
    "        noise = tf.random.normal(shape = (100,self.latent_dim))\n",
    "        z = Reparameterize(mean,logvar,noise)\n",
    "        generated_sequence = self.decoder(z)\n",
    "        return z,mean,logvar,generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "model = BVAE(k,latent_dim,n_filters,depth,seq_len,feature_dim)\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "\n",
    "@tf.function\n",
    "def train_step(input_sequence):\n",
    "    with tf.GradientTape() as tape:\n",
    "        z,mean,logvar,generated_sequence = model(input_sequence)\n",
    "        loss = LossFunction(z,mean,logvar,generated_sequence,input_sequence)\n",
    "        \n",
    "    gradients = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(1,201):\n",
    "    for input_sequence in (batched_dataset):\n",
    "        train_step(input_sequence)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "    print(\"training loss epoch {}: {}\".format(epoch,train_loss.result()))\n",
    "    train_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9264), started 0:03:00 ago. (Use '!kill 9264' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d1a3763e863569b1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d1a3763e863569b1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/gradient_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
